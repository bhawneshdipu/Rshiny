{
    "collab_server" : "",
    "contents" : "## MyPlots.R ##\n\n\nfunction.MyPlotSpeedBins<-function(pac){\n  renderPlotly({\n    #Plot of aggregation by SpeedBins\n    plot_ly(pac, x = ~Index, y = ~SP1 , name = 'Number of cars in time aggregated')%>%\n      add_trace(y = ~SP1, name = '0-50km/h', mode = 'lines') %>%\n      add_trace(y = ~SP2, name = '50-60km/h', mode = 'lines') %>%\n      add_trace(y = ~SP3, name = '60-70km/h', mode = 'lines') %>%\n      add_trace(y = ~SP4, name = '70-80km/h', mode = 'lines') %>%\n      add_trace(y = ~SP5, name = '80-90km/h', mode = 'lines') %>%\n      add_trace(y = ~SP6, name = '90-100km/h', mode = 'lines') %>%\n      add_trace(y = ~SP7, name = '100-110km/h', mode = 'lines') %>%\n      add_trace(y = ~SP8, name = '110-120km/h', mode = 'lines') %>%\n      add_trace(y = ~SP9, name = '120-130km/h', mode = 'lines') %>%\n      add_trace(y = ~SP10, name = '130-140km/h', mode = 'lines') %>%\n      add_trace(y = ~SP11, name = '140-150km/h', mode = 'lines') %>%\n      add_trace(y = ~SP12, name = '150-160km/h', mode = 'lines') %>%\n      add_trace(y = ~SP13, name = '160-180km/h', mode = 'lines')%>%\n      add_trace(y = ~SP14, name = '180-999km/h', mode = 'lines')%>%\n      add_trace(y = ~SUM, name = 'TOTAL', mode = 'lines')\n    \n  })\n}\n\nfunction.MyPlotLengthBins<-function(pac){\n  renderPlotly({\n    #Plot of aggregation by LengthBins\n    plot_ly(pac, x = ~Index, y = ~LN1 , name = 'Number of cars in time aggregated')%>%\n      add_trace(y = ~LN1, name = '0-300 cm', mode = 'lines') %>%\n      add_trace(y = ~LN2, name = '300-470 cm', mode = 'lines') %>%\n      add_trace(y = ~LN3, name = '470-550 cm', mode = 'lines') %>%\n      add_trace(y = ~LN4, name = '550-600 cm', mode = 'lines') %>%\n      add_trace(y = ~LN5, name = '600-1300 cm', mode = 'lines') %>%\n      add_trace(y = ~LN6, name = '1300-1800 cm', mode = 'lines') %>%\n      add_trace(y = ~LN7, name = '1800-2550 cm', mode = 'lines') %>%\n      add_trace(y = ~LN8, name = '2550-3600 cm', mode = 'lines') %>%\n      add_trace(y = ~LN9, name = '3600-9999 cm', mode = 'lines') \n  })\n  \n}\n\nfunction.MyPlotWeightBins<-function(pac){\n  renderPlotly({\n    #Plot of aggregation by WeigthBins\n    plot_ly(data1, x = ~Date, y = ~CS1 , name = 'Number of cars in time aggregated')%>%\n      add_trace(y = ~CS1, name = '0-2000 kg', mode = 'lines') %>%\n      add_trace(y = ~CS2, name = '2000-3501 kg', mode = 'lines') %>%\n      add_trace(y = ~CS3, name = '3501-7497 kg', mode = 'lines') %>%\n      add_trace(y = ~CS4, name = '7497-12002 kg', mode = 'lines') %>%\n      add_trace(y = ~CS5, name = '12002-17998  kg', mode = 'lines') %>%\n      add_trace(y = ~CS6, name = '17998-23999  kg', mode = 'lines') \n  })\n}\n\nfunction.MyBoxPlot1<-function(pac){\n  renderPlotly({\n  #boxplot\n    plot_ly(pac,y = ~SP1, name = '0-50km/h',type = 'box')%>%\n      add_trace(y = ~SP2, name = '50-60km/h', mode = 'lines') %>%\n      add_trace(y = ~SP3, name = '60-70km/h', mode = 'lines') %>%\n      add_trace(y = ~SP4, name = '70-80km/h', mode = 'lines') %>%\n      add_trace(y = ~SP5, name = '80-90km/h', mode = 'lines') %>%\n      add_trace(y = ~SP6, name = '90-100km/h', mode = 'lines') %>%\n      add_trace(y = ~SP7, name = '100-110km/h', mode = 'lines') %>%\n      add_trace(y = ~SP8, name = '110-120km/h', mode = 'lines') %>%\n      add_trace(y = ~SP9, name = '120-130km/h', mode = 'lines') %>%\n      add_trace(y = ~SP10, name = '130-140km/h', mode = 'lines') %>%\n      add_trace(y = ~SP11, name = '140-150km/h', mode = 'lines') %>%\n      add_trace(y = ~SP12, name = '150-160km/h', mode = 'lines') %>%\n      add_trace(y = ~SP13, name = '160-180km/h', mode = 'lines')%>%\n      add_trace(y = ~SP14, name = '180-999km/h', mode = 'lines')%>%\n      layout(title = \"Boxplot by day of week\")\n})\n  \n}\nfunction.MyBoxPlot2<-function(pac,x,y,color){\n  renderPlotly({ \n    \n   plot_ly(pac,x = ~get(x),y = ~get(y), color = ~get(color),type = \"box\")%>%\n      layout(boxmode = \"group\")\n    # plot_ly(pac,x = ~SUM,y = ~SP11, color = pac['wday.lbl'],type = \"box\")%>%\n    #      layout(boxmode = \"group\")\n  })\n  \n}\n\nfunction.MyAnomalyDetection<-function(pac,myX,myY,Myperiod,MylastOnly){\n  #==================================Anomaly detection=======================================\n  \n  View(c(myX,myY,Myperiod,MylastOnly,0))\n  #SUM_DATA <- pac[,c(1,12)]\n  \n  myX<-paste0(myX)\n  myY<-paste0(myY)\n  Myperiod<-2\n  MylastOnly<-FALSE\n  SUM_DATA <- pac[,c(grep(paste0(myX),colnames(pac)),grep(paste0(myY), colnames(pac)))]\n  #View(SUM_DATA)\n  View(c(myX,myY,Myperiod,MylastOnly,1))\n  abc <- as.numeric(rownames(SUM_DATA))\n  ggplot(pac, aes(x=myX, y=myY)) + geom_line()\n  \n  #ggplot(pac, aes(x=Index, y=SP11)) + geom_line()\n  #res = AnomalyDetectionTs(SUM_DATA, max_anoms=0.01, direction=\"pos\", plot=TRUE, e_value = T)\n  #res = AnomalyDetectionVec(SUM_DATA[,2], max_anoms=0.01, period=96, direction='both',\n  #                          only_last=FALSE, plot=TRUE)\n  #View(SUM_DATA)\n  \n  res = AnomalyDetectionVec(SUM_DATA[,2], max_anoms=0.01, period=Myperiod, direction='both',\n                            only_last=MylastOnly, plot=TRUE)\n  anomaly_table=res$anoms\n  \n  #SUM_DATA$Index_row <- abc\n  \n  SUM_DATA[[paste0(myX,\"_row\")]] <- abc\n  \n  #anomaly_table<-merge(SUM_DATA,anomaly_table,by.x = \"Index_row\",by.y = \"index\")\n  View(anomaly_table)\n  View(SUM_DATA)\n  View(c(dim(anomaly_table)))\n  if(is.null(anomaly_table)){\n    anomaly_table<-anomaly_table\n  }else{\n    anomaly_table<-\n      \n                    tryCatch({\n                                merge(SUM_DATA,anomaly_table,by.x = paste0(myX,\"_row\"),by.y = \"index\")\n                                \n                                },error=function(cond){\n                                  message(\"Error in anomaly_table\")\n                                  anomaly_table\n                                  \n                                },warning=function(cond){\n                                  message(\"Warning in anomaly_table\")\n                                  anomaly_table\n                                },finally={\n                                  message(\"Warning of anomaly_table\")\n                              }\n                    )\n  }\n  \n  renderPlotly({\n  plot_ly(SUM_DATA, x = ~get(myX), y = ~get(myY))%>%\n    add_trace(colors = \"orange\",name = \"Po?etnos? ?ut v ?ase\",mode = \"lines\")%>%\n    add_trace(y = ~anoms, colors = \"gray\",name = \"Anom?lie\", mode = \"markers\", alpha = 1,data = anomaly_table)%>%\n    layout(title = \"Graf\",\n           xaxis = list(title = \"Čas\",\n                        rangeslider = list(type = \"date\")),\n           yaxis = list(title = \"Početnosť áut\"))\n  })\n}\n\n\nfunction.MyMotifDiscovery<-function(pac,myX,myY){\n  #==================================Motif discovery=======================================\n  \n  res.wcc <- Func.motif(\n    ts = pac[paste0(myX)],\n    global.norm = T,\n    local.norm = F,\n    window.size = 24,\n    overlap = 0,\n    w = 6,\n    a = 5,\n    mask.size = 5,\n    max.dist.ratio = 1.2,\n    count.ratio.1 = 1.1,\n    count.ratio.2 = 1.1\n    )\n  #res.wcc <- Func.motif(ts = pac$SP11, global.norm = T, local.norm = F, window.size = 24, overlap = 0, w = 6, a = 5, mask.size = 5, max.dist.ratio = 1.2, count.ratio.1 = 1.1, count.ratio.2 = 1.1)\n  \n  #res.ahu <- Func.motif(ts = pac$SP12, global.norm = T, local.norm = F, window.size = 24, overlap = 0, w = 6, a = 5, mask.size = 5, max.dist.ratio = 1.2, count.ratio.1 = 1.1, count.ratio.2 = 1.1)\n  res.ahu <- Func.motif(ts = pac[paste0(myY)], global.norm = T, local.norm = F, window.size = 24, overlap = 0, w = 6, a = 5, mask.size = 5, max.dist.ratio = 1.2, count.ratio.1 = 1.1, count.ratio.2 = 1.1)\n  \n  \n  #Visualization\n  data.wcc <- Func.visual.SingleMotif(single.ts = pac[paste0(myY)], window.size = 24, motif.indices = res.wcc$Indices)\n  data.ahu <- Func.visual.SingleMotif(single.ts = pac[paste0(myY)], window.size = 24, motif.indices = res.ahu$Indices)\n  \n  #Determine the total number of motifs discovered in the time series of WCC\n  n <- length(unique(data.wcc$data.1$Y))\n  #Make the plot\n  p<-ggplot(data = data.wcc$data.1) +  \n    geom_line(aes(x = 1:dim(data.wcc$data.1)[1], y = X)) +\n    geom_point(aes(x = 1:dim(data.wcc$data.1)[1], y = X, color=Y, shape=Y))+\n    scale_shape_manual(values = seq(from = 1, to = n)) +\n    guides(shape=guide_legend(nrow = 2)) +\n    xlab(\"Time (15-min)\") + ylab(\"Počet áut\") +\n    theme(panel.background=element_rect(fill = \"white\", colour = \"black\"),\n          legend.position=\"top\",\n          legend.title=element_blank())\n  \n  ggplotly(p)\n}\n\n#=========================MACHINE LEARNING========================\n\nfunction.MyMachineLearning<-function(data1){\n\n# Shuffle row indices: rows\nrows <- sample(nrow(data1))\n\n# Randomly order data: Sonar\ndata1 <- data1[rows,]\n\n# Identify row to split on: split\nsplit <- round(nrow(data1) * .60)\n\n# Create train\ntrain <- data1[1:split,]\n\n# Create test\ntest <- data1[(split + 1):nrow(data1),]\n#------------------------------------------\n\n# Run algorithms using 10-fold cross validation\ncontrol <- trainControl(method=\"cv\", number=10)\nmetric <- \"Accuracy\"\nvalidation_index <- createDataPartition(data1$CHANNEL, p=0.80, list=FALSE)\n# select 20% of the data for validation\nvalidation <- data1[-validation_index,]\n# use the remaining 80% of data to training and testing the models\ndataset <- data1[validation_index,]\n# a) linear algorithms\nset.seed(7)\nfit.lda <- train(SP10 ~ Date_Time,data=data1, method=\"lda\", metric=metric, trControl=control)\n# b) nonlinear algorithms\n# CART\nset.seed(7)\nfit.cart <- train(SP10 ~ Date_Time,data=data1, method=\"rpart\", metric=metric, trControl=control)\n# kNN\nset.seed(7)\nfit.knn <- train(SP10 ~ Date_Time,data=data1, method=\"knn\", metric=metric, trControl=control)\n# c) advanced algorithms\n# SVM\nset.seed(7)\nfit.svm <- train(SP10 ~ Date_Time,data=data1, method=\"svmRadial\", metric=metric, trControl=control)\n# Random Forest\nset.seed(7)\nfit.rf <- train(SP10 ~ Date_Time,data=data1, method=\"rf\", metric=metric, trControl=control)\n\n\n#summarize accuracy of models\nresults <- resamples(list(lda=fit.lda, cart=fit.cart, knn=fit.knn, svm=fit.svm, rf=fit.rf))\nsummary(results)\ndotplot(results)\nprint(fit.lda)\n\n\n# estimate skill of LDA on the validation dataset\npredictions <- predict(fit.lda, validation)\nconfusionMatrix(predictions, validation$CHANNEL)\n}\n\nfunction.MyLinearRegression<-function(pac){\n  \n  #====================================timetk + linear regression: MAPE = 4.3% (timetk demo)==================================\n  \n  \n  SUM_DATA <- pac[,c(1,31)]\n  \n  SUM_DATA %>%\n    tk_index() %>%\n    tk_get_timeseries_summary() %>%\n    glimpse()\n  \n  beer_sales_tbl_aug <- SUM_DATA %>%\n    tk_augment_timeseries_signature()\n  \n  beer_sales_tbl_aug\n  beer_sales_tbl_aug<-na.omit(beer_sales_tbl_aug)\n  \n  (l <- sapply(beer_sales_tbl_aug, function(x) is.factor(x)))\n  m <- beer_sales_tbl_aug[, l]\n  ifelse(n <- sapply(m, function(x) length(levels(x))) == 1, \"DROP\", \"NODROP\")\n  \n  fit_lm <- lm(SUM~ ., data = select(beer_sales_tbl_aug, -c(Index, diff,month.lbl)))\n  \n  summary(fit_lm)\n  #na.omit(fit_lm)\n  \n  beer_sales_idx <- SUM_DATA %>%\n    tk_index()\n  \n  tail(beer_sales_idx)\n  \n  # Make future index\n  future_idx <- beer_sales_idx %>%\n    tk_make_future_timeseries(n_future =10)\n  \n  future_idx\n  \n  new_data_tbl <- future_idx %>%\n    tk_get_timeseries_signature()\n  \n  new_data_tbl\n  \n  # Make predictions\n  pred <- predict(fit_lm, newdata = select(new_data_tbl, -c(index, diff)))\n  predictions_tbl <- tibble(\n    Index  = future_idx,\n    value = pred\n  )\n  \n  predictions_tbl\n  \n  \n  split <- round(nrow(SUM_DATA) * .90)\n  datat_to <- SUM_DATA[1:split,]\n  actuals_tbl <- SUM_DATA[(split + 1):nrow(SUM_DATA),]\n  #colnames(actuals_tbl)[2] <- \"value\"\n  \n  \n  p<-ggplot(SUM_DATA,aes(x=Index,y=SUM))+\n    # Training data\n    geom_line(color = palette_light()[[1]]) +\n    geom_point(color = palette_light()[[1]])+\n    # Predictions\n    geom_line(aes(y = value), color = palette_light()[[4]], data = predictions_tbl) +\n    geom_point(aes(y = value), color = palette_light()[[4]], data = predictions_tbl)+ \n    # Actuals\n    geom_line(aes(y = SUM),color = palette_light()[[3]], data = actuals_tbl) +\n    geom_point(aes(y = SUM),color = palette_light()[[3]], data = actuals_tbl)+\n    theme_tq() +\n    labs(title = \"Time series sum data\")\n  return (ggplotly(p)) \n  \n  \n  \n  error_tbl <- left_join(actuals_tbl, predictions_tbl) %>%\n    rename(actual = SUM, pred = value) %>%\n    mutate(\n      error     = actual - pred,\n      error_pct = error / actual\n    ) \n  error_tbl\n  \n  # Calculating test error metrics\n  test_residuals <- error_tbl$error\n  test_error_pct <- error_tbl$error_pct * 100 # Percentage error\n  \n  me   <- mean(test_residuals, na.rm=TRUE)\n  rmse <- mean(test_residuals^2, na.rm=TRUE)^0.5\n  mae  <- mean(abs(test_residuals), na.rm=TRUE)\n  mape <- mean(abs(test_error_pct), na.rm=TRUE)\n  mpe  <- mean(test_error_pct, na.rm=TRUE)\n  \n  tibble(me, rmse, mae, mape, mpe) %>% glimpse()\n  \n  \n  \n  # Coerce to xts\n  beer_sales_xts <- tk_xts(SUM_DATA) \n  \n  # Show the first six rows of the xts object\n  beer_sales_xts %>%\n    head()\n  tk_tbl(beer_sales_xts, rename_index = \"date\")\n  \n  # Coerce to ts\n  beer_sales_ts <- tk_ts(SUM_DATA)\n  \n  # Show the calendar-printout\n  beer_sales_ts\n  tk_tbl(beer_sales_ts, rename_index = \"date\")\n  \n  has_timetk_idx(beer_sales_ts)\n  \n  # If timetk_idx is present, can get original dates back \n  tk_tbl(beer_sales_ts, timetk_idx = TRUE, rename_index = \"date\")\n  \n  \n}\n\n#====================================ARIMA + sweep: MAPE = 4.3% (sweep demo)==================================\n\n\nfunction.MyArima<-function(pac){\n  \n  \n  SUM_DATA <- pac[,c(1,31)]\n  SUM_DATA %>%\n    ggplot(aes(Index, SUM)) +\n    geom_line(col = palette_light()[1]) +\n    geom_point(col = palette_light()[1]) +\n    geom_ma(ma_fun = SMA, n = 12, size = 1) +\n    theme_tq() +\n    labs(title = \"Beer Sales: 2007 through 2016\")\n  \n  \n  beer_sales_ts <- tk_ts(SUM_DATA)\n  beer_sales_ts\n  has_timetk_idx(beer_sales_ts)\n  fit_arima <- auto.arima(beer_sales_ts)\n  \n  fit_arima\n  # sw_tidy - Get model coefficients\n  sw_tidy(fit_arima)\n  # sw_glance - Get model description and training set accuracy measures\n  sw_glance(fit_arima) %>%\n    glimpse()\n  \n  # sw_augment - get model residuals\n  sw_augment(fit_arima, timetk_idx = TRUE)\n  \n  sw_augment(fit_arima, timetk_idx = TRUE) %>%\n    ggplot(aes(x = index, y = .resid)) +\n    geom_point() + \n    geom_hline(yintercept = 0, color = \"red\") + \n    labs(title = \"Residual diagnostic\") +\n    theme_tq()\n  \n  # Forecast next 12 months\n  fcast_arima <- forecast(fit_arima, h = 100)\n  class(fcast_arima)\n  \n  # Check if object has timetk index \n  has_timetk_idx(fcast_arima)\n  \n  # sw_sweep - tidies forecast output\n  fcast_tbl <- sw_sweep(fcast_arima, timetk_idx = TRUE)\n  \n  fcast_tbl\n  \n  \n  \n  \n  # Visualize the forecast with ggplot\n  fcast_tbl %>%\n    ggplot(aes(x = index, y = SUM, color = key)) +\n    # 95% CI\n    geom_ribbon(aes(ymin = lo.95, ymax = hi.95), \n                fill = \"#D5DBFF\", color = NA, size = 0) +\n    # 80% CI\n    geom_ribbon(aes(ymin = lo.80, ymax = hi.80, fill = key), \n                fill = \"#596DD5\", color = NA, size = 0, alpha = 0.8)+\n    # Prediction\n    geom_line() +\n    geom_point() +\n    # Actuals\n    geom_line(aes(x = Index, y = SUM), color = palette_light()[[1]], data = actuals_tbl) +\n    geom_point(aes(x = Index, y = SUM), color = palette_light()[[1]], data = actuals_tbl)+ \n    # Aesthetics\n    labs(title = \"Beer Sales Forecast: ARIMA\", x = \"\", y = \"Thousands of Tons\",\n         subtitle = \"sw_sweep tidies the auto.arima() forecast output\") +\n    scale_color_tq() +\n    scale_fill_tq() +\n    theme_tq()\n  \n  \n  \n  \n  \n  rror_tbl <- left_join(actuals_tbl, fcast_tbl, by = c(\"Index\" = \"index\"))%>% \n    rename(actual = SUM.x, pred = SUM.y) %>%\n    select(Index, actual, pred) %>%\n    mutate(\n      error     = actual - pred,\n      error_pct = error / actual\n    ) \n  error_tbl\n  na.omit(error_tbl)\n  # Calculate test error metrics\n  test_residuals <- error_tbl$error\n  test_error_pct <- error_tbl$error_pct * 100 # Percentage error\n  \n  me   <- mean(test_residuals, na.rm=TRUE)\n  rmse <- mean(test_residuals^2, na.rm=TRUE)^0.5\n  mae  <- mean(abs(test_residuals), na.rm=TRUE)\n  mape <- mean(abs(test_error_pct), na.rm=TRUE)\n  mpe  <- mean(test_error_pct, na.rm=TRUE)\n  \n  tibble(me, rmse, mae, mape, mpe) %>% glimpse()\n  \n  \n}",
    "created" : 1522654286488.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2273071896",
    "id" : "AA63BC24",
    "lastKnownWriteTime" : 1522787138,
    "last_content_update" : 1522787138628,
    "path" : "~/fiverr/Rshiny/MyPlots.R",
    "project_path" : "MyPlots.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 7,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}